---
title: "Comparison with other methods"
author: "Wei Jiang"
date: "5/10/2018"
output: html_notebook
---
We want to now assess the performance of algorithm SAEM and compare SAEM to several other existing methods for missing data.

```{r}
library(misaem)
library(MASS)
library(mvtnorm)
library(mice)
library(ggplot2)
library(RColorBrewer)
library(tidyr)
theme_set(theme_bw())
```

Here we first assign the true values of parameters.

(By using different values, we can construct different setting, such as number of subjects $n$ or structure of correlation.)
```{r}
n <- 10000  # number of subjects
# n <- 1000 # or a smaller number of subjects 

p <- 5     # number of explanatory variables
mu.star <- 1:p  # mean of the explanatory variables
sd <- 1:p # standard deviations

# with correlation
C <- matrix(c(   # correlation matrix
  1,   0.8, 0,   0,   0,
  0.8, 1,   0,   0,   0,
  0,   0,   1,   0.3, 0.6,
  0,   0,   0.3, 1,   0.7,
  0,   0,   0.6, 0.7, 1
), nrow=p)
## or without correlation
# C = diag(p)

Sigma.star <- diag(sd)%*%C%*%diag(sd) # variance-covariance matrix of the explanatory variables

beta.star <- c(0.5, -0.3, 1, 0, -0.6) # coefficients of logistic regression
beta0.star <- -0.2  # intercept
beta.true = c(beta0.star,beta.star)

#percentage of missingness
p.miss <- 0.10 
patterns = runif(n*p)<p.miss

```

We considered the following competitors:
* The complete case (CC) method : all rows containing at least one unobserved data value were removed)
* Multiple imputation based on conditional modeling as implemented in the R package *mice* (with its default settings and Rubin's combining rules)
* MCEM algorithm that we implemented using adaptive rejection sampling (MCEM-AR). 
* We use the dataset without missing values (no NA) as a reference, with parameters estimated with the Newton-Raphson algorithm as implemented in the *glm* function in R.

We run repetitions of simulations. And evaluate their performance, intially in terms of estimation errors of the parameters, as well as the standard error of estimation and the coverage of confidence interval.

```{r}
nbsim = 1000
EST.saem = EST.comp = EST.cc = EST.mice = matrix(0, nbsim,length(beta.star)+1)
TIME.saem = TIME.mice = rep(0, nbsim)
STD.saem = STD.comp = STD.cc = STD.mice = matrix(0, nbsim,length(beta.star)+1)
LENGTH.saem = LENGTH.comp = LENGTH.cc = LENGTH.mice= matrix(0, nbsim,length(beta.star)+1)
count.saem = count.comp = count.cc =  count.mice = rep(0,p+1)

for (NB in 1:nbsim){
  set.seed(NB)
  # complete data simulation
  X.complete <- matrix(rnorm(n*p), nrow=n)%*%chol(Sigma.star) + matrix(rep(mu.star,n), nrow=n, byrow = TRUE)
  p1 <- 1/(1+exp(-X.complete%*%beta.star-beta0.star))
  y <- as.numeric(runif(n)<p1)
  
  # ----- No NA : classical estimation in the case without missingness
  data.complete <- data.frame(y=y,X.complete)
  model.complete <- glm(y ~.,family=binomial(link='logit'),data=data.complete)
  beta0.complete <- model.complete$coefficients[1]
  beta.complete <- model.complete$coefficients[2:(p+1)]
  P <- predict(model.complete, type = "response")
  W <- diag(P*(1-P))
  X <- model.matrix(model.complete)
  V_complete <- solve(t(X)%*%W%*%X)
  std.complete <- sqrt(diag(V_complete))
  
  # generating missing data - MCAR missingness
  X.obs <- X.complete
  patterns = runif(n*p)<p.miss
  X.obs[patterns] <- NA
  
  ## generating missing data - MAR missingness
  # X.obs <- X.complete
  # for(i in c(2,4,5)){
  #   z <- cbind(y,X.complete[,c(1,3)])%*%matrix(sample(-5:5, 3, replace=T),ncol=1) # linear combination 
  #   pr <- 1/(1+exp(-z))         # pass through an inv-logit function
  #   r <- rbinom(n,1,pr)      # bernoulli response variable
  #   X.obs[r==0,i]<-NA
  # }
  # cat('percentage of NA: ', mean(is.na(X.obs[,2])),mean(is.na(X.obs[,4])),mean(is.na(X.obs[,5])),'\n')
  # 
  
  # ------- CC : estimation ignoring the missing data
  data.obs <- data.frame(y=y,X.obs)
  model.obs <- glm(y ~.,family=binomial(link='logit'),data=data.obs)
  beta0.cc <- model.obs$coefficients[1]
  beta.cc <- model.obs$coefficients[2:(p+1)]
  P <- predict(model.obs, type = "response")
  W <- diag(P*(1-P))
  X <- model.matrix(model.obs)
  V_cc <- solve(t(X)%*%W%*%X)
  std.cc <- sqrt(diag(V_cc))
  
  # ------- mice : multiple imputation
  ptm <- Sys.time()
  DATA.ch= cbind.data.frame(y,X.obs)
  imp.ch <- mice(DATA.ch,print = FALSE)
  fit.ch <- glm.mids(y~., data=imp.ch,family = binomial)
  beta.mice=summary(pool(fit.ch, method = "rubin1987"))[,1]
  std.mice=summary(pool(fit.ch, method = "rubin1987"))[,2]
  time.mice=Sys.time() - ptm
  
  # -------  SAEM
  list.saem=miss.saem(X.obs,y, print_iter=FALSE,var_cal=TRUE)
  beta.saem = list.saem$beta
  std.saem = list.saem$std_obs
  
  EST.comp[NB,] = c(beta0.complete,beta.complete)
  EST.cc[NB,] = c(beta0.cc,beta.cc)
  EST.saem[NB,] = beta.saem
  EST.mice[NB,] = beta.mice
  
  STD.comp[NB,] = std.complete
  STD.cc[NB,] = std.cc
  STD.saem[NB,] = std.saem
  STD.mice[NB,] = std.mice
  
  TIME.saem[NB] = list.saem$time_run
  TIME.mice[NB] = time.mice
  
  ci.comp_ceil =  c(beta0.complete,beta.complete) + 1.96*std.complete
  ci.comp_ground =  c(beta0.complete,beta.complete) - 1.96*std.complete
  ci.cc_ceil =  c(beta0.cc,beta.cc) + 1.96*std.cc
  ci.cc_ground =  c(beta0.cc,beta.cc) - 1.96*std.cc
  ci.saem_ceil = beta.saem + 1.96*std.saem
  ci.saem_ground = beta.saem - 1.96*std.saem
  ci.mice_ceil = beta.mice + 1.96*std.mice
  ci.mice_ground = beta.mice - 1.96*std.mice
  
  LENGTH.comp[NB,] = ci.comp_ceil - ci.comp_ground
  LENGTH.cc[NB,] = ci.cc_ceil - ci.cc_ground
  LENGTH.saem[NB,] = ci.saem_ceil - ci.saem_ground
  LENGTH.mice[NB,] = ci.mice_ceil - ci.mice_ground
  for(i in 1:(p+1)){
    if( ci.comp_ground[i] <=beta.true[i] & ci.comp_ceil[i]>beta.true[i]){
      count.comp[i]<-count.comp[i]+1
    }
    if( ci.cc_ground[i] <=beta.true[i] & ci.cc_ceil[i]>beta.true[i]){
      count.cc[i]<-count.cc[i]+1
    }
    if( ci.saem_ground[i] <=beta.true[i] & ci.saem_ceil[i]>beta.true[i]){
      count.saem[i]<-count.saem[i]+1
    }
    if( ci.mice_ground[i] <=beta.true[i] & ci.mice_ceil[i]>beta.true[i]){
      count.mice[i]<-count.mice[i]+1
    }
  }
}
```

Now we change the setting with a smaller size of observation:
```{r}
n <- 1000  # number of subjects

p <- 5     # number of explanatory variables
mu.star <- 1:p  # mean of the explanatory variables
sd <- 1:p # standard deviations

# with correlation
C <- matrix(c(   # correlation matrix
  1,   0.8, 0,   0,   0,
  0.8, 1,   0,   0,   0,
  0,   0,   1,   0.3, 0.6,
  0,   0,   0.3, 1,   0.7,
  0,   0,   0.6, 0.7, 1
), nrow=p)

Sigma.star <- diag(sd)%*%C%*%diag(sd) # variance-covariance matrix of the explanatory variables

beta.star <- c(0.5, -0.3, 1, 0, -0.6) # coefficients of logistic regression
beta0.star <- -0.2  # intercept
beta.true = c(beta0.star,beta.star)

#percentage of missingness
p.miss <- 0.10 


nbsim = 1000
EST.small.saem = EST.small.comp = EST.small.cc = EST.small.mice = matrix(0, nbsim,length(beta.star)+1)
TIME.small.saem = TIME.small.mice = rep(0, nbsim)
STD.small.saem = STD.small.comp = STD.small.cc = STD.small.mice = matrix(0, nbsim,length(beta.star)+1)
LENGTH.small.saem = LENGTH.small.comp = LENGTH.small.cc = LENGTH.small.mice= matrix(0, nbsim,length(beta.star)+1)
count.small.saem = count.small.comp = count.small.cc =  count.small.mice = rep(0,p+1)

for (NB in 1:nbsim){
  set.seed(NB)
  # complete data simulation
  X.small.complete <- matrix(rnorm(n*p), nrow=n)%*%chol(Sigma.star) + matrix(rep(mu.star,n), nrow=n, byrow = TRUE)
  p1 <- 1/(1+exp(-X.small.complete%*%beta.star-beta0.star))
  y <- as.numeric(runif(n)<p1)
  
  # ----- No NA : classical estimation in the case without missingness
  data.small.complete <- data.frame(y=y,X.small.complete)
  model.small.complete <- glm(y ~.,family=binomial(link='logit'),data=data.small.complete)
  beta0.small.complete <- model.small.complete$coefficients[1]
  beta.small.complete <- model.small.complete$coefficients[2:(p+1)]
  P <- predict(model.small.complete, type = "response")
  W <- diag(P*(1-P))
  X <- model.matrix(model.small.complete)
  V_complete <- solve(t(X)%*%W%*%X)
  std.small.complete <- sqrt(diag(V_complete))
  
  # generating missing data - MCAR missingness
  X.obs <- X.small.complete
  patterns = runif(n*p)<p.miss
  X.obs[patterns] <- NA
  
  # ------- CC : estimation ignoring the missing data
  data.obs <- data.frame(y=y,X.obs)
  model.obs <- glm(y ~.,family=binomial(link='logit'),data=data.obs)
  beta0.small.cc <- model.obs$coefficients[1]
  beta.small.cc <- model.obs$coefficients[2:(p+1)]
  P <- predict(model.obs, type = "response")
  W <- diag(P*(1-P))
  X <- model.matrix(model.obs)
  V_cc <- solve(t(X)%*%W%*%X)
  std.small.cc <- sqrt(diag(V_cc))
  
  # ------- mice : multiple imputation
  ptm <- Sys.time()
  DATA.ch= cbind.data.frame(y,X.obs)
  imp.ch <- mice(DATA.ch,print = FALSE)
  fit.ch <- glm.mids(y~., data=imp.ch,family = binomial)
  beta.small.mice=summary(pool(fit.ch, method = "rubin1987"))[,1]
  std.small.mice=summary(pool(fit.ch, method = "rubin1987"))[,2]
  time.small.mice=Sys.time() - ptm
  
  # -------  SAEM
  list.small.saem=miss.saem(X.obs,y, print_iter=FALSE,var_cal=TRUE)
  beta.small.saem = list.small.saem$beta
  std.small.saem = list.small.saem$std_obs
  
  EST.small.comp[NB,] = c(beta0.small.complete,beta.small.complete)
  EST.small.cc[NB,] = c(beta0.small.cc,beta.small.cc)
  EST.small.saem[NB,] = beta.small.saem
  EST.small.mice[NB,] = beta.small.mice
  
  STD.small.comp[NB,] = std.small.complete
  STD.small.cc[NB,] = std.small.cc
  STD.small.saem[NB,] = std.small.saem
  STD.small.mice[NB,] = std.small.mice
  
  TIME.small.saem[NB] = list.small.saem$time_run
  TIME.small.mice[NB] = time.small.mice
  
  ci.small.comp_ceil =  c(beta0.small.complete,beta.small.complete) + 1.96*std.small.complete
  ci.small.comp_ground =  c(beta0.small.complete,beta.small.complete) - 1.96*std.small.complete
  ci.small.cc_ceil =  c(beta0.small.cc,beta.small.cc) + 1.96*std.small.cc
  ci.small.cc_ground =  c(beta0.small.cc,beta.small.cc) - 1.96*std.small.cc
  ci.small.saem_ceil = beta.small.saem + 1.96*std.small.saem
  ci.small.saem_ground = beta.small.saem - 1.96*std.small.saem
  ci.small.mice_ceil = beta.small.mice + 1.96*std.small.mice
  ci.small.mice_ground = beta.small.mice - 1.96*std.small.mice
  
  LENGTH.small.comp[NB,] = ci.small.comp_ceil - ci.small.comp_ground
  LENGTH.small.cc[NB,] = ci.small.cc_ceil - ci.small.cc_ground
  LENGTH.small.saem[NB,] = ci.small.saem_ceil - ci.small.saem_ground
  LENGTH.small.mice[NB,] = ci.small.mice_ceil - ci.small.mice_ground
  for(i in 1:(p+1)){
    if( ci.small.comp_ground[i] <=beta.true[i] & ci.small.comp_ceil[i]>beta.true[i]){
      count.small.comp[i]<-count.small.comp[i]+1
    }
    if( ci.small.cc_ground[i] <=beta.true[i] & ci.small.cc_ceil[i]>beta.true[i]){
      count.small.cc[i]<-count.small.cc[i]+1
    }
    if( ci.small.saem_ground[i] <=beta.true[i] & ci.small.saem_ceil[i]>beta.true[i]){
      count.small.saem[i]<-count.small.saem[i]+1
    }
    if( ci.small.mice_ground[i] <=beta.true[i] & ci.small.mice_ceil[i]>beta.true[i]){
      count.small.mice[i]<-count.small.mice[i]+1
    }
  }
}
```

We compare the bias of estimation by observing the boxplots. For example, bias of estimated $\beta_3$:

```{r}
#pdf('bias.pdf',width = 12, height = 5 ,onefile = T) # save as pdf
palette(brewer.pal(6, "Dark2"))
for(i in 4:4){
df <- data.frame(n10000=c(EST.cor.comp[,i]-beta.true[i],EST.cor.cc[,i]-beta.true[i],EST.cor.mice[,i]-beta.true[i],EST.cor.saem[,i]-beta.true[i]),n1000=c(EST.cor.small.comp[,i]-beta.true[i],EST.cor.small.cc[,i]-beta.true[i],EST.cor.small.mice[,i]-beta.true[i],EST.cor.small.saem[,i]-beta.true[i]),
                 method=factor(c(rep(1,100),rep(2,100),rep(3,100),rep(4,100)),labels=c("no NA","CC","mice","SAEM")))
dg = gather(df,'Param','Value',1:2)
dg[['Param']] = as.factor(dg[['Param']])
levels(dg[['Param']]) <- c("n = 1000", "n = 10000")

if(i==1){yexp =expression("Bias of "*hat(beta)[0])}
if(i==2){yexp =expression("Bias of "*hat(beta)[1])}
if(i==3){yexp =expression("Bias of "*hat(beta)[2])}
if(i==4){yexp =expression("Bias of "*hat(beta)[3])}
if(i==5){yexp =expression("Bias of "*hat(beta)[4])}
if(i==6){yexp =expression("Bias of "*hat(beta)[5])}

g =  ggplot(dg, aes(x=method, y=Value)) +      
  
  stat_boxplot(geom ='errorbar', width = 0.4)+
  geom_boxplot() +
  geom_hline(yintercept=0,linetype="dashed",color='red3') +
  labs(x="", y = yexp) +
  facet_grid( ~ Param)+
theme(strip.text = element_text(size=14),axis.title=element_text(size=14),axis.text.x =element_text(size=14),axis.text.y =element_text(size=14))
print(g)
}
```

And the variance of estimation
```{r}
#pdf('se2.pdf',width = 12, height = 5 ,onefile = T) # save as pdf
for(i in 4:4){
df <- data.frame(n10000=c(STD.cor.comp[,i],STD.cor.cc[,i],STD.cor.mice[,i],STD.cor.saem[,i]),n1000=c(STD.cor.small.comp[,i],STD.cor.small.cc[,i],STD.cor.small.mice[,i],STD.cor.small.saem[,i]),
                 method=factor(c(rep(1,100),rep(2,100),rep(3,100),rep(4,100)),labels=c("no NA","CC","mice","SAEM")))
dg = gather(df,'Param','Value',1:2)
dg[['Param']] = as.factor(dg[['Param']])
levels(dg[['Param']]) <- c("n = 1000", "n = 10000")
dg[['EST']]=c(EST.cor.comp[,i],EST.cor.cc[,i],EST.cor.mice[,i],EST.cor.saem[,i],EST.cor.small.comp[,i],EST.cor.small.cc[,i],EST.cor.small.mice[,i],EST.cor.small.saem[,i])

if(i==1){yexp =expression("Standard error of "*hat(beta)[0])}
if(i==2){yexp =expression("Standard error of "*hat(beta)[1])}
if(i==3){yexp =expression("Standard error of "*hat(beta)[2])}
if(i==4){yexp =expression("Standard error of "*hat(beta)[3])}
if(i==5){yexp =expression("Standard error of "*hat(beta)[4])}
if(i==6){yexp =expression("Standard error of "*hat(beta)[5])}

fmt_dcimals <- function(decimals=0){
   # return a function responpsible for formatting the 
   # axis labels with a given number of decimals 
   function(x) as.character(round(x,decimals))
}
g =  ggplot(dg, aes(x=method, y=Value)) +  
  stat_boxplot(geom ='errorbar', width = 0.4)+
  geom_boxplot() +
  labs(x="", y = yexp) +
  facet_grid( ~Param, scales="free")+
stat_summary(aes(y = EST),fun.y='sd', colour="red3", geom="point", 
               shape=18, size=4,show.legend = FALSE)+
# scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
#                     labels = trans_format("log10", math_format(10^.x)))+
theme(strip.text = element_text(size=14),axis.title=element_text(size=14),axis.text.x =element_text(size=14),axis.text.y =element_text(size=14))

print(g)

}
```


MAR
```{r}
#pdf('mar.pdf',width = 12, height = 5 ,onefile = T) # save as pdf
palette(brewer.pal(6, "Dark2"))
for(i in 4:4){
df <- data.frame(n1000=c(EST.mar.cor.small.comp[,i]-beta.true[i],EST.mar.cor.small.cc[,i]-beta.true[i],EST.mar.cor.small.mice[,i]-beta.true[i],EST.mar.cor.small.saem[,i]-beta.true[i]),n10000=c(EST.mary.cor.comp[,i]-beta.true[i],EST.mary.cor.cc[,i]-beta.true[i],EST.mary.cor.mice[,i]-beta.true[i],EST.mary.cor.saem[,i]-beta.true[i]),
                 method=factor(c(rep(1,100),rep(2,100),rep(3,100),rep(4,100)),labels=c("no NA","CC","mice","SAEM")))
dg = gather(df,'Param','Value',1:2)
dg[['Param']] = as.factor(dg[['Param']])
levels(dg[['Param']]) <- c( "MAR, only depends on x","MAR, depends on y")

if(i==1){yexp =expression("Bias of "*hat(beta)[0])}
if(i==2){yexp =expression("Bias of "*hat(beta)[1])}
if(i==3){yexp =expression("Bias of "*hat(beta)[2])}
if(i==4){yexp =expression("Bias of "*hat(beta)[3])}
if(i==5){yexp =expression("Bias of "*hat(beta)[4])}
if(i==6){yexp =expression("Bias of "*hat(beta)[5])}

g =  ggplot(dg, aes(x=method, y=Value)) +      
  stat_boxplot(geom ='errorbar', width = 0.4)+
  geom_boxplot() +
  geom_hline(yintercept=0,linetype="dashed",color='red3') +
  labs(x="", y = yexp) +
  facet_wrap( ~Param,scales = 'free' )+
theme(strip.text = element_text(size=14),axis.title=element_text(size=14),axis.text.x =element_text(size=14),axis.text.y =element_text(size=14))
print(g)
}
```

Correlation
```{r}
#pdf('cor.pdf',width = 12, height = 5 ,onefile = T) # save as pdf
palette(brewer.pal(6, "Dark2"))
for(i in 4:4){
df <- data.frame(n1000=c(EST.cor.comp[,i]-beta.true[i],EST.cor.cc[,i]-beta.true[i],EST.cor.mice[,i]-beta.true[i],EST.cor.saem[,i]-beta.true[i]),n10000=c(EST.comp[,i]-beta.true[i],EST.cc[,i]-beta.true[i],EST.mice[,i]-beta.true[i],EST.saem[,i]-beta.true[i]),
                 method=factor(c(rep(1,100),rep(2,100),rep(3,100),rep(4,100)),labels=c("no NA","CC","mice","SAEM")))
dg = gather(df,'Param','Value',1:2)
dg[['Param']] = as.factor(dg[['Param']])
levels(dg[['Param']]) <- c( "With correlation","Without correlation")

if(i==1){yexp =expression("Bias of "*hat(beta)[0])}
if(i==2){yexp =expression("Bias of "*hat(beta)[1])}
if(i==3){yexp =expression("Bias of "*hat(beta)[2])}
if(i==4){yexp =expression("Bias of "*hat(beta)[3])}
if(i==5){yexp =expression("Bias of "*hat(beta)[4])}
if(i==6){yexp =expression("Bias of "*hat(beta)[5])}

g =  ggplot(dg, aes(x=method, y=Value)) +   
    stat_boxplot(geom ='errorbar', width = 0.4)+
  geom_boxplot() +
  geom_hline(yintercept=0,linetype="dashed",color='red3') +
  labs(x="", y = yexp) +
  facet_grid( ~Param,scales = 'free' )+
theme(strip.text = element_text(size=14),axis.title=element_text(size=14),axis.text.x =element_text(size=14),axis.text.y =element_text(size=14))
print(g)
}
```