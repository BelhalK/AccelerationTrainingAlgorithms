{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karimimohammedbelhal/Desktop/ongoing/hostnfly/deeptech/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(object):\n",
    "  def __init__(self, dropout=0.5):\n",
    "    self._input = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "    self._training = tf.placeholder_with_default(False, shape=[])\n",
    "    self._labels = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "    out = self._input\n",
    "    if dropout:\n",
    "      out = tf.layers.dropout(out, rate=0.2 if dropout > 0.2 else dropout, training=self._training)\n",
    "    out = self.conv2d(out, filters=6, name='layer0') # 24\n",
    "    out = tf.layers.max_pooling2d(out, pool_size=2, strides=2) # 12\n",
    "    if dropout:\n",
    "      out = tf.layers.dropout(out, rate=dropout, training=self._training)\n",
    "    out = self.conv2d(out, filters=16, name='layer1') # 8\n",
    "\n",
    "    out = tf.layers.max_pooling2d(out, pool_size=2, strides=2) # 4\n",
    "    if dropout:\n",
    "      out = tf.layers.dropout(out, rate=dropout, training=self._training)\n",
    "    out = tf.contrib.layers.flatten(out)\n",
    "    out = self.dense(out, filters=120, name='layer2')\n",
    "    if dropout:\n",
    "      out = tf.layers.dropout(out, rate=dropout, training=self._training)\n",
    "    out = self.dense(out, filters=84, name='layer3')\n",
    "    if dropout:\n",
    "      out = tf.layers.dropout(out, rate=dropout, training=self._training)\n",
    "    out = self.dense(out, filters=10, name='layer4')\n",
    "    self._inference_op = out\n",
    "\n",
    "    correct = tf.equal(tf.argmax(self._labels, 1), tf.argmax(self._inference_op, 1))\n",
    "    self._accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "  @classmethod\n",
    "  def conv2d(cls, input, filters, name=None):\n",
    "    return tf.layers.conv2d(input, filters=filters, kernel_size=5, activation=tf.nn.relu, name=name)\n",
    "\n",
    "  @classmethod\n",
    "  def dense(cls, input, filters, name=None):\n",
    "    return tf.layers.dense(input, filters, activation=tf.nn.relu, name=name)\n",
    "\n",
    "  def setup_train(self, average_gradients=1, lr=1e-3):\n",
    "    self._average_gradients = average_gradients\n",
    "    self._loss_op = tf.losses.softmax_cross_entropy(onehot_labels=self._labels, logits=self._inference_op)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "    if average_gradients == 1:\n",
    "      # This 'train_op' computes gradients and applies them in one step.\n",
    "      self._train_op = optimizer.minimize(self._loss_op)\n",
    "    else:\n",
    "      # here 'train_op' only applies gradients passed via placeholders stored\n",
    "      # in 'grads_placeholders. The gradient computation is done with 'grad_op'.\n",
    "      grads_and_vars = optimizer.compute_gradients(self._loss_op)\n",
    "      avg_grads_and_vars = []\n",
    "      self._grad_placeholders = []\n",
    "      for grad, var in grads_and_vars:\n",
    "        grad_ph = tf.placeholder(grad.dtype, grad.shape)\n",
    "        self._grad_placeholders.append(grad_ph)\n",
    "        avg_grads_and_vars.append((grad_ph, var))\n",
    "      self._grad_op = [x[0] for x in grads_and_vars]\n",
    "      self._train_op = optimizer.apply_gradients(avg_grads_and_vars)\n",
    "      self._gradients = [] # list to store gradients\n",
    "\n",
    "  def train(self, session, input_batch, output_batch):\n",
    "    feed_dict = {\n",
    "      self._input: input_batch,\n",
    "      self._labels: output_batch,\n",
    "      self._training: True\n",
    "    }\n",
    "    if self._average_gradients == 1:\n",
    "      loss, _ = session.run([self._loss_op, self._train_op], feed_dict=feed_dict)\n",
    "    else:\n",
    "      loss, grads = session.run([self._loss_op, self._grad_op], feed_dict=feed_dict)\n",
    "      self._gradients.append(grads)\n",
    "      if len(self._gradients) == self._average_gradients:\n",
    "        for i, placeholder in enumerate(self._grad_placeholders):\n",
    "          feed_dict[placeholder] = np.stack([g[i] for g in self._gradients], axis=0).mean(axis=0)\n",
    "        session.run(self._train_op, feed_dict=feed_dict)\n",
    "        self._gradients = []\n",
    "    return loss\n",
    "\n",
    "  def evaluate(self, session, input_batch, output_labels):\n",
    "    feed_dict = {\n",
    "      self._input: input_batch,\n",
    "      self._labels: output_labels\n",
    "    }\n",
    "    return session.run(self._accuracy_op, feed_dict=feed_dict) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-216ab0e3dcd4>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/karimimohammedbelhal/Desktop/ongoing/hostnfly/deeptech/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/karimimohammedbelhal/Desktop/ongoing/hostnfly/deeptech/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/karimimohammedbelhal/Desktop/ongoing/hostnfly/deeptech/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/karimimohammedbelhal/Desktop/ongoing/hostnfly/deeptech/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/karimimohammedbelhal/Desktop/ongoing/hostnfly/deeptech/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/karimimohammedbelhal/Desktop/ongoing/hostnfly/deeptech/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_DATA', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(average_gradients, batch_size, iterations, verbose):\n",
    "  batch_size = batch_size\n",
    "  tf.reset_default_graph()\n",
    "  net = ConvNet()\n",
    "\n",
    "  validation_batch = mnist.test.images\n",
    "  val_count = validation_batch.shape[0]\n",
    "  validation_batch = np.reshape(validation_batch, (val_count, 28, 28, 1))\n",
    "  validation_labels = mnist.test.labels\n",
    "\n",
    "  net.setup_train(average_gradients=average_gradients)\n",
    "  training_log = []\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(iterations):\n",
    "      batch = mnist.train.next_batch(batch_size)\n",
    "      input_batch = np.reshape(batch[0], (batch_size, 28, 28, 1))\n",
    "      loss = net.train(sess, input_batch, batch[1])\n",
    "      if (i+1) % 100 == 0:\n",
    "        accuracy = net.evaluate(sess, validation_batch, validation_labels)\n",
    "        training_log.append((accuracy, i+1))\n",
    "        if verbose:\n",
    "          print('[{:d}/{:d}] loss: {:.3g}, accuracy: {:.3g}%'.format(i+1, iterations, loss, accuracy))\n",
    "    accuracy = net.evaluate(sess, validation_batch, validation_labels)\n",
    "    training_log.append((accuracy, iterations))\n",
    "    best = sorted(training_log, key=lambda x: x[0], reverse=True)[0]\n",
    "    print('Training finished. Best accuracy: {:.3g} at iteration {:d}.'.format(best[0], best[1]))\n",
    "    return best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/100] loss: 2.16, accuracy: 29.6%\n",
      "Training finished. Best accuracy: 29.6 at iteration 100.\n",
      "[100/100] loss: 2.14, accuracy: 33.3%\n",
      "Training finished. Best accuracy: 33.3 at iteration 100.\n"
     ]
    }
   ],
   "source": [
    "accuracies = [run_experiment(average_gradients=1, batch_size = 100, iterations=100, verbose= True) for i in range(2)]\n",
    "print('mean accuracy ({:d} runs): {:.3g} +/- {:.3g}'.format(2, np.mean(accuracies), np.std(accuracies)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeptech",
   "language": "python",
   "name": "deeptech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
